{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 1\n",
    "\n",
    "O desafio 1 é sobre a extração, limpeza e manipulação de dados no INEP sobre o Censo da Educação Superior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DADOS \n",
    "\n",
    "Estão disponíveis no site do Inep os Microdados do Censo da Educação Superior 2018 (DM_IES, DM_CURSO, DM_DOCENTE, DM_ALUNO, DM_LOCAL_OFERTA e TB_AUX_AREA_OCDE) em formato CSV delimitados por Pipe ( | ). Os arquivos encontram-se compactados (em formato .zip) pelo software 7-zip.  \n",
    "\n",
    "\n",
    "#### ANEXO I – Dicionários de dados e Tabelas Auxiliares \n",
    "\n",
    "Contém, em formato .xlsx (Excel), o Dicionário de Dados do Censo da Educação Superior 2018 e também uma tabela auxiliar com o código e o nome dos países: \n",
    "\n",
    "1.DICIONÁRIO DE DADOS \n",
    "\n",
    "- TABELA DE ALUNO \n",
    "- TABELA DE CURSO \n",
    "- TABELA DE IES \n",
    "- TABELA DE LOCAL DE OFERTA \n",
    "- TABELA DE DOCENTE \n",
    "- TABELA AUXILIAR OCDE \n",
    " \n",
    "2.TABELA CONTENDO O NOME DO PAÍS DE ORIGEM OU NATURALIZAÇÃO \n",
    " \n",
    "#### ANEXO II – Questionários do Censo da Educação Superior  \n",
    "\n",
    "Contém, em formato .pdf (Portable Document Format), os seguintes questionários do Censo da Educação Superior 2018 e estão disponíveis para download na pasta anexos: \n",
    "\n",
    "- MÓDULO IES \n",
    "- MÓDULO CURSO \n",
    "- MÓDULO DOCENTE \n",
    "- MÓDULO ALUNO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura e preparação inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9e6ad7a8409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \"\"\"\n\u001b[1;32m--> 388\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                     rv_frozen)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_nnls\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnnls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_basinhopping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinprog_verbose_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lsap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_differentialevolution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_linprog.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptimizeResult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptimizeWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_ip\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_ip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_simplex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_simplex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_linprog_rs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_linprog_rs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import random\n",
    "import glob\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo total de linhas de DM_ALUNO sem importar o dataset\n",
    "with open ('dados/DM_ALUNO.csv') as f:\n",
    "    total_linhas = sum(1 for row in f)-1\n",
    "    \n",
    "total_linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando um array de números aleatórios de 1 até total_linhas de tamanho = drop (99%)\n",
    "percent_amostra = 0.01\n",
    "amostra = int(percent_amostra * total_linhas)\n",
    "drop = total_linhas - amostra\n",
    "\n",
    "skip = random.sample(range(1,total_linhas),drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo o dataset com skiprows = 99% dos dados, gerando uma amostra de 1%. \n",
    "df_alunos = pd.read_csv('dados/DM_ALUNO.csv', sep='|', encoding='latin1', skiprows=skip)\n",
    "df_alunos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo os demais datasets\n",
    "df_ies = pd.read_csv('dados/DM_IES.CSV', sep='|', encoding='latin1')\n",
    "df_curso = pd.read_csv('dados/DM_CURSO.CSV', sep='|', encoding='latin1')\n",
    "df_docente = pd.read_csv('dados/DM_DOCENTE.CSV', sep='|', encoding='latin1')\n",
    "df_local = pd.read_csv('dados/DM_LOCAL_OFERTA.CSV', sep='|', encoding='latin1')\n",
    "df_cine = pd.read_csv('dados/TB_AUX_CINE_BRASIL.CSV', sep='|', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Crie duas tabelas: uma com número de universidades públicas e privadas por estado e outra com número de alunos por universidade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidades Públicas e Privadas por estado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Usando a tabela do IBGE para atrelar código do estado a UF.\n",
    "estados = pd.read_excel(\"dados/Tabela Estados IBGE.xlsx\")\n",
    "estados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estados = estados.rename(columns={'Código da UF':'CO_UF','UF':'SG_UF'}).drop('Estado',axis=1)\n",
    "estados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que define universidade pública ou privada a partir de TP_CATEGORIA_ADMINISTRATIVA.\n",
    "def publi_privada(categoria_adm):\n",
    "    if categoria_adm < 3:\n",
    "        return 'Universidade Pública'\n",
    "    elif categoria_adm != 7:\n",
    "        return 'Universidade Privada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrega estados ao df de uni / Aplica a função criando nova coluna como resposta / Agrupa por estado e tipo somando IES\n",
    "df_publi_privada = df_ies.merge(estados)\n",
    "df_publi_privada['TIPO_UNI'] = df_publi_privada['TP_CATEGORIA_ADMINISTRATIVA'].apply(publi_privada)\n",
    "df_publi_privada.groupby(['SG_UF','TIPO_UNI']).agg(TOTAL_UNI = ('CO_IES','nunique'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de alunos por universidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agega o nome da universidade / Agrupa pelo nome da uni e conta o número de alunos ordenando de forma descendente\n",
    "df_alunos_uni = df_alunos.merge(df_ies[['CO_IES','NO_IES']])\n",
    "df_alunos_uni = df_alunos_uni.groupby('NO_IES', as_index=False).agg(\n",
    "                                                N_ALUNOS = ('ID_ALUNO','nunique')).sort_values(by='N_ALUNOS',ascending=False)\n",
    "df_alunos_uni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como é uma amostra de 1% do total, pode-se multiplicar por 1/percent_amostra para se aproximar do número total de alunos\n",
    "df_alunos_uni['N_ALUNOS'] = (df_alunos_uni['N_ALUNOS'] * 1/percent_amostra).astype(int)\n",
    "df_alunos_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Pergunta-se: é verdade que existem menos mulheres nos cursos de exatas? Explique com os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_cine[['CO_CINE_AREA_GERAL','NO_CINE_AREA_GERAL']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota-se que 5, 6 e 7 são cursos de exatas.\n",
    "exatas = [5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrega o nome e código da área ao df_alunos e atribui a df_exatas\n",
    "df_exatas = df_alunos.merge(df_cine[['CO_CINE_ROTULO', 'CO_CINE_AREA_GERAL', 'NO_CINE_AREA_GERAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mantém em df_exatas somente os alunos que o cód da área esteja em exatas.\n",
    "df_exatas = df_exatas.loc[df_exatas['CO_CINE_AREA_GERAL'].isin(exatas),['ID_ALUNO','TP_SEXO','NO_CINE_AREA_GERAL']]\n",
    "df_exatas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para garantir que df_exatas não tem alunos duplicados. \n",
    "df_exatas = df_exatas.drop_duplicates(subset='ID_ALUNO')\n",
    "df_exatas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de mulheres nos cursos de exatas',df_exatas.loc[df_exatas['TP_SEXO']==1,'ID_ALUNO'].count())\n",
    "print(f'Total de homens nos cursos de exatas',df_exatas.loc[df_exatas['TP_SEXO']==2,'ID_ALUNO'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato existem menos mulheres do que homens nos cursos de exatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Quantos cursos novos abrem por ano? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novos_cursos = df_curso.dropna(subset=['DT_INICIO_FUNCIONAMENTO']).copy()\n",
    "df_novos_cursos['DT_INICIO_FUNCIONAMENTO'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_novos_cursos['DT_INICIO_FUNCIONAMENTO'] = pd.to_datetime(df_novos_cursos['DT_INICIO_FUNCIONAMENTO'],format='%d/%m/%Y')\n",
    "#Ao tentar converter a coluna para data, nota-se que há um erro de digitação em uma das linhas. \n",
    "df_novos_cursos['DT_INICIO_FUNCIONAMENTO'] = df_novos_cursos['DT_INICIO_FUNCIONAMENTO'].str.replace('2917','2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora sim, convertendo a coluna e criando uma nova apenas com o ano de inicio.\n",
    "df_novos_cursos['DT_INICIO_FUNCIONAMENTO'] = pd.to_datetime(df_novos_cursos['DT_INICIO_FUNCIONAMENTO'],format='%d/%m/%Y')\n",
    "df_novos_cursos['ANO_INICIO_FUNCIONAMENTO'] = df_novos_cursos['DT_INICIO_FUNCIONAMENTO'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupando pelo ano e inicio e contando os cursos\n",
    "df_novos_cursos = (df_novos_cursos.groupby('ANO_INICIO_FUNCIONAMENTO', as_index=False).\n",
    "                       agg(N_NOVOS_CURSOS = ('CO_CURSO','count')).sort_values(by='ANO_INICIO_FUNCIONAMENTO', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considerando um periodo de 10 anos.\n",
    "anos = 10\n",
    "ult = df_novos_cursos['ANO_INICIO_FUNCIONAMENTO'].max()\n",
    "df_novos_cursos = df_novos_cursos.loc[df_novos_cursos['ANO_INICIO_FUNCIONAMENTO'] >= ult - anos]\n",
    "df_novos_cursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Abrem em média {int(df_novos_cursos[\"N_NOVOS_CURSOS\"].mean())} novos cursos por ano')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) A afirmação a seguir é verdadeira: Alunos da região Norte têm maior tendência a não concluírem os cursos quando comparados ao restante do país? Comprove com dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando desistente os alunos que trancaram a matrícula ou estão desvinculados do curso (códigos 3 e 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrega código de UF e IES ao df_alunos em df_desistente / Desistente = 1 - Não desistente = 0 /Remove alunos duplicados\n",
    "df_desistente = df_alunos.merge(df_ies[['CO_IES','CO_UF']])\n",
    "df_desistente['DESISTENTE'] = np.where((df_desistente['TP_SITUACAO'] == 3) | (df_desistente['TP_SITUACAO'] == 4),1,0)\n",
    "df_desistente = df_desistente.drop_duplicates(subset=['ID_ALUNO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estados da Região Norte e respecitvos CO_UF:\n",
    "- Acre: 12\n",
    "- Amapá: 16\n",
    "- Amazonas: 13\n",
    "- Pará: 15\n",
    "- Rondônia: 11\n",
    "- Roraima: 14\n",
    "- Tocantins: 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando em dois dataframes alunos da região norte e demais regiões.\n",
    "norte = [11,12,13,14,15,16,17]\n",
    "df_alunos_norte = df_desistente.loc[df_desistente['CO_UF'].isin(norte)]\n",
    "df_alunos_outras = df_desistente.loc[~df_desistente['CO_UF'].isin(norte)]\n",
    "df_alunos_norte.shape, df_alunos_outras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('O indice de desistência da região Norte é de {:.2f} %'.\n",
    "      format((df_alunos_norte.loc[df_alunos_norte['DESISTENTE']==1, 'DESISTENTE'].count() * 100) / df_alunos_norte.shape[0]))\n",
    "print('O indice de desistência de outras regiões é de {:.2f} %'.\n",
    "      format((df_alunos_outras.loc[df_alunos_outras['DESISTENTE']==1, 'DESISTENTE'].count() * 100) / df_alunos_outras.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A afirmação é falsa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5) Crie uma variável que represente a taxa de abandono para cada IES. É correto afirmar professores mais/menos capacitados influenciam tal taxa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo professores duplicados / Agrupando por IES / Tirando a média de escolaridade dos professores\n",
    "df_prof = df_docente.drop_duplicates(subset='ID_DOCENTE')\n",
    "df_prof = df_prof.groupby('CO_IES', as_index = False).agg(ESCOLARIDADE = ('TP_ESCOLARIDADE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupando alunos desistentes por IES / Calculando Taxa de abondono \n",
    "df_desistente = df_desistente.groupby('CO_IES', as_index=False).agg(TAXA_ABANDONO = ('DESISTENTE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando os os dois dataframes\n",
    "df_aluno_docente = df_prof.merge(df_desistente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a correlação entre a escolaridade do professor e a taxa de abandono. \n",
    "pearson, p_pearson = stats.pearsonr(df_aluno_docente['ESCOLARIDADE'], df_aluno_docente['TAXA_ABANDONO'])\n",
    "spearman, p_spearman = stats.spearmanr(df_aluno_docente['ESCOLARIDADE'], df_aluno_docente['TAXA_ABANDONO'])\n",
    "\n",
    "print(f'Correlação de Pearson: {round(pearson, 2)}, com p-valor de {round(p_pearson, 3)}')\n",
    "print(f'Correlação de Spearman: {round(spearman, 2)}, com p-valor de {round(p_spearman, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como o p-valor da correlação de Pearson e de Spearman é menor do que 0.05 há um fraca correlação.\n",
    "- A correlação negativa nos diz que quanto maior a escolaridade, menor a taxa de abandono nas IES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Quais os cursos com maior crescimento de matriculas por região? E quais os com maior queda? Como você explicaria isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando mapa de estados por região\n",
    "regiao = {'Norte' : [11, 12, 13, 14, 15, 16, 17],\n",
    "          'Nordeste' : [21, 22, 23 ,24, 25, 26, 27, 28, 29],\n",
    "          'Centro-Oeste' : [50, 51, 52, 53],\n",
    "          'Sudeste' : [31, 32, 33, 35],\n",
    "          'Sul' : [41, 42, 43]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trazendo as colunas com código e nome do curso e código do estado\n",
    "df_matriculas = df_alunos.merge(df_curso[['CO_CURSO','NO_CURSO','CO_UF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para classificar a região do curso a partir do CO_UF\n",
    "def reg_estado(co_uf, regiao):\n",
    "    for reg in regiao.keys():\n",
    "        if co_uf in regiao[reg]:\n",
    "            return reg\n",
    "        \n",
    "df_matriculas['REGIAO'] = df_matriculas['CO_UF'].apply(reg_estado, args=(regiao,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupando por região, curso e ano. / Calculando o número de mátriculas por região, curso e ano. \n",
    "df_matriculas = df_matriculas.groupby(['REGIAO','NO_CURSO','NU_ANO_INGRESSO'], as_index=False).agg\\\n",
    "                                                                                        (N_MATRICULAS = ('ID_ALUNO','nunique'))\n",
    "df_matriculas['N_MATRICULAS'] = df_matriculas['N_MATRICULAS'] / percent_amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando os anos de 2017 e 2018\n",
    "df_matriculas = df_matriculas.loc[df_matriculas['NU_ANO_INGRESSO'].isin([2018,2017])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando colunas separadas com matrículas de 2017 e 2018 / Renomeando colunas / Dropando valores nulos\n",
    "df_matriculas = df_matriculas.pivot(index=['REGIAO','NO_CURSO'], columns=['NU_ANO_INGRESSO'],values=['N_MATRICULAS'])\n",
    "df_matriculas = df_matriculas.reset_index()\n",
    "df_matriculas.columns=['REGIAO','NO_CURSO','MATRICULAS_2017','MATRICULAS_2018']\n",
    "df_matriculas.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a difereça de uma ano pra outro\n",
    "df_matriculas['AUMENTO_MATRICULAS'] = df_matriculas['MATRICULAS_2018'] - df_matriculas['MATRICULAS_2017']\n",
    "df_matriculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando dataframes para maiores e menores matriculas por região. \n",
    "df_maiores = pd.DataFrame(columns=df_matriculas.columns)\n",
    "df_menores = pd.DataFrame(columns=df_matriculas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append nos 5 maiores cursos de cada região\n",
    "for regiao in df_matriculas['REGIAO'].unique():\n",
    "    aux = df_matriculas.loc[df_matriculas['REGIAO'] == regiao]\n",
    "    df_maiores = df_maiores.append(aux.nlargest(5, 'AUMENTO_MATRICULAS'))\n",
    "    df_menores = df_menores.append(aux.nsmallest(5, 'AUMENTO_MATRICULAS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_menores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
